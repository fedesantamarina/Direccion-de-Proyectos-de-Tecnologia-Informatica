<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Clase 14: Testing y Aseguramiento de Calidad de Software - UAI</title>
    <link rel="stylesheet" href="styles.css">
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>
</head>
<body>
    <header>
        <div class="header-content">
            <div class="logo">
                <h1>UAI - Especialización en Dirección de Proyectos TI</h1>
            </div>
            <nav class="main-nav">
                <a href="index.html">Inicio</a>
                <a href="index.html#about">Sobre la Carrera</a>
                <a href="index.html#contact">Contacto</a>
            </nav>
        </div>
    </header>

    <div class="container">
        <aside class="sidebar">
            <h2>Contenido del Curso</h2>
            <nav class="chapters-nav">
                <ul>
                    <li><a href="clase-01.html">Clase 1: Introducción a la Dirección de Proyectos TI</a></li>
                    <li><a href="clase-02.html">Clase 2: Fundamentos de la Gestión de Proyectos</a></li>
                    <li><a href="clase-03.html">Clase 3: Metodologías Tradicionales</a></li>
                    <li><a href="clase-04.html">Clase 4: Metodologías Ágiles</a></li>
                    <li><a href="clase-05.html">Clase 5: Planificación y Gestión del Alcance</a></li>
                    <li><a href="clase-06.html">Clase 6: Gestión del Tiempo y Cronogramas</a></li>
                    <li><a href="clase-07.html">Clase 7: Gestión de Costos y Presupuestos</a></li>
                    <li><a href="clase-08.html">Clase 8: Gestión de Riesgos</a></li>
                    <li><a href="clase-09.html">Clase 9: Ingeniería de Requerimientos</a></li>
                    <li><a href="clase-10.html">Clase 10: Métricas de Software</a></li>
                    <li><a href="clase-11.html">Clase 11: Calidad del Software y Estándares</a></li>
                    <li><a href="clase-12.html">Clase 12: Gestión del Capital Humano</a></li>
                    <li><a href="clase-13.html">Clase 13: Arquitectura y Diseño de Software</a></li>
                    <li><a href="clase-14.html" class="active">Clase 14: Testing y Aseguramiento de Calidad</a></li>
                    <li><a href="clase-15.html">Clase 15: DevOps y Entrega Continua</a></li>
                    <li><a href="clase-16.html">Clase 16: Tendencias Emergentes</a></li>
                </ul>
            </nav>
        </aside>

        <main class="main-content">
            <article>
                <h1>Clase 14: Testing y Aseguramiento de Calidad de Software</h1>

                <section>
                    <h2>1. Niveles de Testing: Unitario, Integración, Sistema, Aceptación</h2>

                    <p>
                        El testing de software se estructura en niveles jerárquicos que reflejan diferentes granularidades de
                        verificación y distintos objetivos de calidad. Esta organización en niveles facilita detección temprana
                        de defectos, aislamiento de causas raíz, y distribución efectiva de esfuerzos de testing. La comprensión
                        profunda de estos niveles resulta esencial para directores de proyectos que deben planificar estrategias
                        de testing, asignar recursos apropiadamente y establecer criterios de salida (exit criteria) para cada fase.
                    </p>

                    <p>
                        El testing unitario verifica la corrección de componentes individuales de software, típicamente funciones,
                        métodos o clases, de manera aislada. Los tests unitarios son ejecutados por desarrolladores durante la
                        implementación, frecuentemente siguiendo prácticas de Test-Driven Development. Las características distintivas
                        incluyen: alcance estrecho (testing de unidad mínima testeable), ejecución rápida (milisegundos por test),
                        aislamiento mediante mocks y stubs para dependencias externas, y determinismo (mismo input produce mismo
                        output consistentemente). El testing unitario proporciona retroalimentación inmediata sobre corrección del
                        código y facilita refactorización segura mediante detección rápida de regresiones.
                    </p>

                    <p>
                        El testing de integración verifica las interfaces y interacciones entre componentes o subsistemas.
                        Mientras que los tests unitarios aíslan componentes mediante mocks, los tests de integración verifican
                        que componentes reales trabajen correctamente juntos. Los enfoques de integración varían: la integración
                        big bang integra todos los componentes simultáneamente y luego testea el sistema completo, simple pero
                        dificulta localización de defectos. La integración incremental añade componentes progresivamente: top-down
                        comienza con módulos de alto nivel y añade módulos de bajo nivel; bottom-up comienza con módulos de bajo
                        nivel y construye hacia arriba; sandwich combina ambos enfoques simultáneamente.
                    </p>

                    <p>
                        El testing de sistema evalúa el sistema completo e integrado para verificar que cumple requisitos
                        especificados. Este nivel de testing adopta una perspectiva de caja negra, enfocándose en comportamiento
                        externo sin preocupación por estructura interna. Los tipos de testing de sistema incluyen: testing funcional
                        (verificación de requisitos funcionales), testing de rendimiento (throughput, latencia bajo carga), testing
                        de seguridad (vulnerabilidades, control de acceso), testing de usabilidad (facilidad de uso, experiencia
                        de usuario) y testing de compatibilidad (diferentes navegadores, sistemas operativos, dispositivos).
                    </p>

                    <p>
                        El testing de aceptación determina si el sistema satisface criterios de aceptación y está listo para
                        entrega. Se distinguen múltiples formas: User Acceptance Testing (UAT) involucra usuarios reales validando
                        que el sistema satisface sus necesidades de negocio; Operational Acceptance Testing (OAT) verifica aspectos
                        operacionales como backup/recovery, instalación, mantenimiento; Contract Acceptance Testing verifica
                        cumplimiento con términos contractuales; y Regulatory Acceptance Testing valida conformidad con regulaciones
                        aplicables. El testing de aceptación típicamente se realiza en ambientes que replican producción tan
                        fielmente como sea posible.
                    </p>

                    <p>
                        La pirámide de testing, conceptualizada por Mike Cohn, proporciona guidance sobre la proporción apropiada
                        de tests en cada nivel. La base amplia de la pirámide representa gran cantidad de tests unitarios (rápidos,
                        baratos, proporcionan retroalimentación inmediata). El nivel medio contiene cantidad moderada de tests de
                        integración (más lentos, más costosos pero verifican interacciones críticas). El ápice estrecho representa
                        pequeña cantidad de tests de UI/sistema end-to-end (lentos, frágiles, costosos de mantener pero validan
                        flujos críticos de usuario). Esta distribución optimiza velocidad de feedback, costo de mantenimiento y
                        confianza en calidad del sistema.
                    </p>

                    <div class="mermaid">
                    graph TD
                        A[Pirámide de Testing] --> B[Nivel 4: Testing Manual Exploratorio]
                        B --> C[Nivel 3: Testing UI/E2E]
                        C --> D[Nivel 2: Testing de Integración]
                        D --> E[Nivel 1: Testing Unitario]
                        B --> B1[Mínima cantidad]
                        B --> B2[Máximo costo]
                        B --> B3[Feedback más lento]
                        C --> C1[Pocos tests]
                        C --> C2[Flujos críticos]
                        C --> C3[Alto costo mantenimiento]
                        D --> D1[Cantidad moderada]
                        D --> D2[Interfaces componentes]
                        D --> D3[Balance costo/valor]
                        E --> E1[Gran cantidad]
                        E --> E2[Rápidos y baratos]
                        E --> E3[Feedback inmediato]
                    </div>
                </section>

                <section>
                    <h2>2. Tipos de Pruebas: Funcionales y No Funcionales</h2>

                    <p>
                        El testing de software abarca una taxonomía amplia de tipos de pruebas, cada uno diseñado para verificar
                        aspectos específicos de calidad del sistema. La categorización fundamental distingue entre testing funcional,
                        que verifica que el sistema hace lo que debe hacer (requisitos funcionales), y testing no funcional, que
                        verifica cómo el sistema desempeña funciones (atributos de calidad como rendimiento, seguridad, usabilidad).
                        Una estrategia de testing comprehensiva debe abordar ambas dimensiones apropiadamente balanceadas según
                        prioridades del proyecto.
                    </p>

                    <p>
                        El testing funcional emplea técnicas de caja negra, tratando el sistema como una entidad opaca donde solo
                        entradas y salidas son observables. Las técnicas incluyen: partición de equivalencia (dividir dominio de
                        entrada en clases donde se espera comportamiento similar), análisis de valores límite (testing en
                        fronteras de particiones donde típicamente ocurren defectos), tablas de decisión (capturar lógica de
                        negocio compleja con múltiples condiciones), testing basado en casos de uso (derivar casos de test de
                        escenarios de usuario), y testing basado en modelos de estado (verificar transiciones válidas e inválidas
                        entre estados del sistema).
                    </p>

                    <p>
                        El testing de rendimiento evalúa la responsividad, throughput, confiabilidad y escalabilidad del sistema
                        bajo cargas de trabajo específicas. El load testing determina comportamiento bajo cargas esperadas,
                        verificando que el sistema cumple SLAs (Service Level Agreements) de rendimiento. El stress testing empuja
                        el sistema más allá de límites operacionales normales para identificar puntos de quiebre. El spike testing
                        evalúa comportamiento ante aumentos súbitos y dramáticos de carga. El endurance testing (soak testing)
                        ejecuta el sistema bajo carga sostenida por períodos prolongados para detectar fugas de memoria, degradación
                        gradual o problemas de estabilidad que solo emergen con tiempo.
                    </p>

                    <p>
                        El testing de seguridad identifica vulnerabilidades, amenazas y riesgos en el sistema. Las técnicas incluyen:
                        testing de penetración (ethical hacking para explotar vulnerabilidades), análisis de vulnerabilidades
                        (scanning automatizado de vulnerabilidades conocidas), security auditing (examen sistemático de controles
                        de seguridad), testing de inyección (SQL injection, XSS, command injection), testing de autenticación y
                        autorización (verificando controles de acceso), y testing de cifrado (validando que datos sensibles están
                        apropiadamente protegidos). En el contexto de regulaciones como GDPR, HIPAA o PCI-DSS, el testing de
                        seguridad y privacidad adquiere importancia crítica y frecuentemente requiere expertise especializado.
                    </p>

                    <p>
                        El testing de usabilidad evalúa la facilidad con que usuarios pueden aprender, operar y alcanzar objetivos
                        usando el sistema. A diferencia de otros tipos de testing mayormente automatizables, el testing de usabilidad
                        típicamente involucra usuarios reales realizando tareas representativas mientras observadores documentan
                        dificultades, confusiones, errores y retroalimentación. Las métricas incluyen: eficacia (si usuarios logran
                        completar tareas), eficiencia (tiempo y esfuerzo requerido), satisfacción (respuesta subjetiva del usuario),
                        curva de aprendizaje (rapidez con que nuevos usuarios se vuelven productivos) y tasa de error (frecuencia
                        de errores de usuario y dificultad de recuperación).
                    </p>

                    <p>
                        El testing de compatibilidad verifica que el sistema funciona correctamente en diferentes ambientes,
                        plataformas, navegadores, dispositivos y configuraciones. Para aplicaciones web, esto incluye testing en
                        múltiples navegadores (Chrome, Firefox, Safari, Edge) y versiones. Para aplicaciones móviles, testing en
                        diferentes dispositivos (teléfonos, tablets), tamaños de pantalla, sistemas operativos (iOS, Android) y
                        versiones. El testing de compatibilidad hacia atrás verifica que nuevas versiones continúan soportando
                        funcionalidad de versiones anteriores. La proliferación de dispositivos y configuraciones hace que el
                        testing de compatibilidad exhaustivo sea prohibitivamente costoso; estrategias pragmáticas priorizan
                        combinaciones más comunes basadas en analytics de uso real.
                    </p>

                    <div class="info-box">
                        <h4>Tipos de Testing No Funcional</h4>
                        <ul>
                            <li><strong>Rendimiento:</strong> Load, Stress, Spike, Endurance, Scalability</li>
                            <li><strong>Seguridad:</strong> Penetration, Vulnerability Analysis, Security Auditing</li>
                            <li><strong>Usabilidad:</strong> Facilidad de uso, Accesibilidad, Experiencia de Usuario</li>
                            <li><strong>Compatibilidad:</strong> Cross-browser, Cross-platform, Cross-device</li>
                            <li><strong>Confiabilidad:</strong> Recovery, Failover, Disaster Recovery</li>
                            <li><strong>Mantenibilidad:</strong> Modularidad, Reusabilidad, Analizabilidad</li>
                        </ul>
                    </div>
                </section>

                <section>
                    <h2>3. Estrategias de Testing en Proyectos Ágiles</h2>

                    <p>
                        El testing en contextos ágiles difiere significativamente de enfoques tradicionales en cascada donde el
                        testing constituye una fase distinta posterior al desarrollo. Los principios ágiles enfatizan testing
                        continuo integrado en todo el ciclo de vida de desarrollo, con testers trabajando colaborativamente con
                        desarrolladores y analistas de negocio desde el inicio del proyecto. El Manifesto Ágil de Testing, articulado
                        por Lisa Crispin y Janet Gregory, propone: testing durante el desarrollo sobre testing después; prevenir
                        defectos sobre encontrar defectos; testers trabajando con desarrolladores sobre verificación independiente;
                        y responder al cambio sobre seguir planes rígidos.
                    </p>

                    <p>
                        El concepto de "todo el equipo" (whole team approach) reconoce que la calidad es responsabilidad colectiva,
                        no solo del equipo de QA. Los desarrolladores escriben tests unitarios y participan en testing exploratorio.
                        Los testers colaboran en refinamiento de requisitos, diseño de casos de test antes de implementación,
                        automatización de tests y análisis de defectos. Los product owners definen criterios de aceptación y
                        participan en testing de aceptación. Esta colaboración multifuncional facilita construcción de calidad
                        desde el inicio en lugar de inspección al final.
                    </p>

                    <p>
                        La pirámide de testing ágil distribuye esfuerzos de testing apropiadamente entre niveles. La base amplia
                        de tests unitarios automatizados proporciona feedback en segundos sobre regresiones. El nivel intermedio
                        de tests de integración verifica interacciones entre componentes. Los tests de API verifican contratos
                        de servicios. Los tests de UI validan flujos críticos de usuario end-to-end. El testing exploratorio manual
                        en el ápice aprovecha creatividad humana para descubrir defectos que tests automatizados no anticipan.
                        Esta distribución equilibra velocidad, costo y cobertura efectivamente.
                    </p>

                    <p>
                        La automatización de testing constituye un enabler crítico de agilidad. Los tests automatizados ejecutados
                        en pipelines de integración continua proporcionan feedback rápido sobre cada cambio de código. Sin embargo,
                        la automatización requiere inversión inicial significativa y mantenimiento continuo. La matriz de Brian
                        Marick categoriza tests en cuatro cuadrantes según si están orientados a tecnología o negocio, y si soportan
                        al equipo o critican el producto. Cuadrante 1 (tecnología, soporte): tests unitarios y de componentes.
                        Cuadrante 2 (negocio, soporte): tests funcionales automatizados. Cuadrante 3 (negocio, crítica): testing
                        exploratorio, escenarios de usuario. Cuadrante 4 (tecnología, crítica): testing no funcional como rendimiento
                        y seguridad.
                    </p>

                    <p>
                        El testing continuo extiende prácticas de integración continua hacia verificación automatizada en cada
                        etapa del pipeline de entrega. Cada commit desencadena ejecución de suite de tests unitarios. Builds exitosos
                        progresan a tests de integración y API. Tests de UI y end-to-end ejecutan en ambientes staging-like.
                        Tests de rendimiento, seguridad y compatibilidad ejecutan en paralelo o progresivamente según duración.
                        Este feedback multi-etapa permite detección temprana de defectos mientras el contexto está fresco en la
                        mente de desarrolladores, facilitando corrección rápida y económica.
                    </p>

                    <p>
                        El testing exploratorio, aunque frecuentemente percibido como ad-hoc, constituye una técnica estructurada
                        donde el diseño de tests y su ejecución ocurren simultáneamente, informados por aprendizaje continuo.
                        Los testers exploratorios usan charters que definen misión, alcance y enfoque de sesiones de testing
                        time-boxed. Durante exploración, los testers aprovechan intuición, experiencia y creatividad para investigar
                        comportamiento del sistema, diseñando tests dinámicamente basados en observaciones. El testing exploratorio
                        complementa testing scripted automatizado al descubrir defectos que nadie pensó testear explícitamente,
                        particularmente problemas de usabilidad, edge cases inusuales y interacciones complejas.
                    </p>

                    <div class="success-box">
                        <h4>Principios de Testing Ágil</h4>
                        <ul class="checklist">
                            <li>Proporcionar feedback continuo sobre calidad del producto</li>
                            <li>Entregar valor al cliente mediante testing orientado a negocio</li>
                            <li>Habilitar colaboración cara a cara entre desarrolladores, testers y stakeholders</li>
                            <li>Tener coraje para reportar información precisa sobre estado del proyecto</li>
                            <li>Mantener simplicidad enfocándose en testing que agrega mayor valor</li>
                            <li>Practicar mejora continua mediante retrospectivas y experimentación</li>
                            <li>Responder al cambio mediante estrategias de testing adaptativas</li>
                        </ul>
                    </div>
                </section>

                <section>
                    <h2>4. Automatización de Pruebas: Herramientas y Frameworks</h2>

                    <p>
                        La automatización de testing constituye una inversión estratégica que permite ejecución repetible, rápida
                        y consistente de tests, liberando a testers humanos para actividades de mayor valor como testing exploratorio,
                        diseño de estrategias de testing y análisis de riesgos de calidad. Sin embargo, la automatización no es
                        panacea; tests mal diseñados o mantenidos inadecuadamente pueden convertirse en liability que ralentiza
                        desarrollo en lugar de acelerarlo. La automatización efectiva requiere inversión deliberada en diseño de
                        tests mantenibles, selección apropiada de herramientas y establecimiento de prácticas de mantenimiento.
                    </p>

                    <p>
                        Los frameworks de testing unitario proporcionan infraestructura para escribir y ejecutar tests de unidades
                        de código. JUnit y TestNG dominan en el ecosistema Java. PyTest y unittest en Python. NUnit y xUnit en .NET.
                        Jest y Mocha en JavaScript/Node.js. Estos frameworks proporcionan: assertions para verificar condiciones
                        esperadas, fixtures para configurar estado de test, test runners para ejecutar suites de tests, y
                        reportes de resultados. Las convenciones de naming, organización de tests y uso de mocks/stubs varían
                        entre frameworks pero principios fundamentales permanecen consistentes.
                    </p>

                    <p>
                        Los frameworks de testing de integración facilitan verificación de interacciones entre componentes.
                        Spring Test proporciona soporte comprehensivo para testing de aplicaciones Spring incluyendo inyección
                        de dependencias, transacciones de test y contexts de aplicación mock. Testcontainers permite ejecutar
                        bases de datos, message brokers y otros servicios en containers Docker durante tests, proporcionando
                        ambientes de integración realistas sin complejidad de gestionar infraestructura persistente. WireMock
                        simula servicios HTTP externos mediante stubbing y mocking, facilitando testing de integraciones con APIs
                        third-party sin dependencias de servicios reales.
                    </p>

                    <p>
                        Los frameworks de testing de UI automatizado permiten simular interacciones de usuario con interfaces
                        gráficas. Selenium WebDriver domina el testing de aplicaciones web, proporcionando APIs para controlar
                        navegadores programáticamente. Cypress ha emergido como alternativa moderna con arquitectura que ejecuta
                        en el mismo loop de ejecución que la aplicación, facilitando debugging y proporcionando espera automática
                        que reduce flakiness. Playwright de Microsoft soporta múltiples navegadores con API unificada y capacidades
                        avanzadas como auto-waiting y web-first assertions. Para aplicaciones móviles, Appium proporciona
                        abstracción sobre iOS y Android, mientras Espresso (Android) y XCUITest (iOS) ofrecen frameworks nativos
                        de plataforma.
                    </p>

                    <p>
                        Los frameworks de testing de API facilitan verificación de interfaces programáticas. REST-assured
                        proporciona DSL Java para testing de APIs REST con assertions expresivas. Postman permite testing manual
                        e automatizado de APIs con colecciones ejecutables en pipelines CI. Pact implementa consumer-driven contract
                        testing, permitiendo que consumidores definan contratos sobre cómo esperan que proveedores se comporten,
                        y verificar que proveedores cumplen estos contratos. Este enfoque facilita testing de microservicios
                        independientes mientras asegura compatibilidad de integraciones.
                    </p>

                    <p>
                        Las herramientas de testing de rendimiento simulan cargas de trabajo para evaluar comportamiento del
                        sistema bajo estrés. JMeter de Apache proporciona capacidades comprehensivas de load testing con soporte
                        para múltiples protocolos. Gatling ofrece DSL Scala para definir escenarios de carga con reportes
                        detallados. K6 permite escribir scripts de load testing en JavaScript con enfoque en developer experience
                        y integración en CI/CD. Locust usa Python para definir comportamiento de usuarios, facilitando escenarios
                        de carga complejos. La interpretación de resultados de performance testing requiere comprensión de métricas
                        como percentiles de latencia, throughput bajo carga sostenida, degradación graceful y recuperación post-stress.
                    </p>

                    <div class="mermaid">
                    graph TD
                        A[Automatización de Testing] --> B[Unit Testing]
                        A --> C[Integration Testing]
                        A --> D[UI Testing]
                        A --> E[API Testing]
                        A --> F[Performance Testing]
                        B --> B1[JUnit/TestNG]
                        B --> B2[PyTest]
                        B --> B3[Jest]
                        C --> C1[Spring Test]
                        C --> C2[Testcontainers]
                        C --> C3[WireMock]
                        D --> D1[Selenium]
                        D --> D2[Cypress]
                        D --> D3[Playwright]
                        E --> E1[REST-assured]
                        E --> E2[Postman]
                        E --> E3[Pact]
                        F --> F1[JMeter]
                        F --> F2[Gatling]
                        F --> F3[K6]
                    </div>
                </section>

                <section>
                    <h2>5. Test-Driven Development (TDD) y BDD</h2>

                    <p>
                        Test-Driven Development representa un enfoque disciplinado de desarrollo donde tests se escriben antes del
                        código de producción, invirtiendo la secuencia tradicional. El ciclo TDD, frecuentemente denominado
                        Red-Green-Refactor, procede iterativamente: Red - escribir un test que falla para funcionalidad deseada;
                        Green - escribir el código mínimo necesario para hacer que el test pase; Refactor - mejorar el código
                        manteniendo los tests pasando. Este ciclo repetido incrementalmente construye funcionalidad con cobertura
                        de tests comprehensiva y diseño emergente guiado por requisitos de testabilidad.
                    </p>

                    <p>
                        Los beneficios de TDD trascienden simple cobertura de tests. La práctica fuerza clarificación de requisitos
                        antes de implementación, reduciendo ambigüedad y trabajo desperdiciado. Los tests documentan comportamiento
                        esperado de manera ejecutable y siempre actualizada. El diseño emergente desde perspectiva de cliente del
                        código (el test) típicamente resulta en APIs más usables y código más desacoplado. Los tests proporcionan
                        safety net para refactorización confiada. La disciplina de escribir código solo para hacer tests pasar
                        previene gold-plating y scope creep a nivel de código.
                    </p>

                    <p>
                        Sin embargo, TDD presenta desafíos. La inversión de tiempo inicial aumenta antes de que productividad
                        mejore. La curva de aprendizaje es sustancial; escribir buenos tests requiere habilidad desarrollada con
                        práctica. El mantenimiento de tests añade overhead continuo. Los tests pueden volverse frágiles, fallando
                        ante cambios legítimos en implementación. El debate sobre efectividad de TDD persiste en literatura empírica
                        con resultados mixtos, sugiriendo que beneficios dependen significativamente de contexto, dominio y
                        competencia del equipo. TDD no debe adoptarse dogmáticamente sino evaluarse pragmáticamente según
                        circunstancias específicas.
                    </p>

                    <p>
                        Behavior-Driven Development extiende TDD hacia especificación de comportamiento del sistema usando lenguaje
                        natural comprensible por stakeholders no técnicos. BDD emplea el formato Given-When-Then para describir
                        escenarios: Given establece precondiciones y contexto inicial; When describe acción o evento que ocurre;
                        Then especifica resultado esperado. Este formato estructura conversaciones sobre comportamiento esperado
                        entre analistas de negocio, desarrolladores y testers, facilitando entendimiento compartido de requisitos.
                    </p>

                    <p>
                        Los frameworks BDD como Cucumber, SpecFlow y Behave permiten escribir especificaciones en lenguaje natural
                        (frecuentemente usando sintaxis Gherkin) que se mapean a código ejecutable mediante step definitions.
                        Por ejemplo: "Given un usuario autenticado, When navega a su perfil, Then debe ver su información personal".
                        Los step definitions implementan la lógica de test correspondiente a cada paso. Esta separación entre
                        especificación de negocio y implementación técnica facilita que stakeholders no técnicos participen en
                        definición de criterios de aceptación mientras desarrolladores mantienen control sobre implementación.
                    </p>

                    <p>
                        La adopción exitosa de BDD requiere más que herramientas; requiere cambio cultural hacia colaboración
                        continua. Los "Three Amigos" - un desarrollador, un tester y un analista de negocio - colaboran en talleres
                        de example mapping o specification workshops para explorar requisitos mediante ejemplos concretos antes de
                        implementación. Esta colaboración temprana reduce ambigüedad, identifica edge cases y construye entendimiento
                        compartido. BDD no es primariamente sobre testing sino sobre especificación mediante ejemplos ejecutables.
                        Los tests automatizados son subproducto valioso de este proceso de especificación colaborativa, no su
                        objetivo principal.
                    </p>

                    <div class="mermaid">
                    graph LR
                        A[Ciclo TDD] --> B[Red: Escribir Test que Falla]
                        B --> C[Green: Implementar Código Mínimo]
                        C --> D[Refactor: Mejorar Diseño]
                        D --> B
                        E[BDD Process] --> F[Discovery: Explorar Requisitos]
                        F --> G[Formulation: Escribir Escenarios Given-When-Then]
                        G --> H[Automation: Implementar Step Definitions]
                        H --> I[Ejecución: Validar Comportamiento]
                    </div>
                </section>

                <section>
                    <h2>6. Cobertura de Código y Métricas de Testing</h2>

                    <p>
                        La cobertura de código (code coverage) mide el grado en que el código fuente es ejecutado por tests
                        automatizados, proporcionando insight cuantitativo sobre thoroughness del testing. Las métricas de cobertura
                        incluyen: cobertura de sentencias (porcentaje de líneas de código ejecutadas), cobertura de ramas (porcentaje
                        de ramas de decisión tomadas), cobertura de funciones (porcentaje de funciones invocadas), y cobertura de
                        condiciones (porcentaje de sub-expresiones booleanas evaluadas en ambos valores verdadero y falso). Las
                        herramientas como JaCoCo, Cobertura, Istanbul y Coverage.py instrumentan código para rastrear ejecución
                        durante tests y generar reportes de cobertura.
                    </p>

                    <p>
                        Sin embargo, cobertura alta no garantiza testing efectivo. Un test puede ejecutar código sin verificar
                        que produce resultados correctos. Cobertura 100% es inalcanzable o impráctica en muchos sistemas reales
                        debido a código de manejo de errores raramente ejecutado, legacy code difícil de testear, o código generado
                        automáticamente. La obsesión con porcentajes de cobertura puede incentivar escribir tests que incrementan
                        métricas sin agregar valor real. La métrica debe usarse como herramienta diagnóstica para identificar áreas
                        no testeadas que requieren atención, no como objetivo en sí mismo ni KPI de calidad de testing.
                    </p>

                    <p>
                        Las métricas de defectos proporcionan insights valiosos sobre efectividad de procesos de calidad. La densidad
                        de defectos (defectos por KLOC - miles de líneas de código, o defectos por punto de función) permite comparar
                        calidad entre componentes o proyectos de diferentes tamaños. La distribución de severidad de defectos
                        (crítico, mayor, menor, trivial) informa priorización de correcciones. La detección de defectos por fase
                        (requisitos, diseño, implementación, testing, producción) revela efectividad de actividades de QA en
                        diferentes etapas. El costo de corrección aumenta exponencialmente cuanto más tarde se detectan defectos,
                        motivando shift-left testing.
                    </p>

                    <p>
                        La eficiencia de remoción de defectos (DRE - Defect Removal Efficiency) mide el porcentaje de defectos
                        detectados antes de liberación: DRE = defectos encontrados pre-release / (defectos pre-release + defectos
                        post-release). DRE de 95% implica que 95% de defectos fueron removidos antes de producción. Esta métrica
                        proporciona indicador agregado de efectividad de procesos de QA. Sin embargo, requiere rastreo cuidadoso
                        de defectos post-release, lo cual puede ser desafiante con usuarios distribuidos globalmente y canales
                        de reporte inconsistentes.
                    </p>

                    <p>
                        Las métricas de velocidad de testing incluyen: tiempo de ejecución de suite de tests (crítico para feedback
                        rápido en CI/CD), frecuencia de ejecución de tests (cuán frecuentemente se ejecutan suites completas),
                        flakiness rate (porcentaje de tests que fallan intermitentemente sin cambios de código), y tiempo de
                        corrección de tests fallidos. Tests lentos o flaky erosionan confianza y eventualmente son ignorados o
                        deshabilitados, degradando efectividad de testing. La inversión en tests determinísticos, rápidos y
                        confiables paga dividendos continuos.
                    </p>

                    <p>
                        El ROI de automatización de testing puede estimarse comparando costos de creación y mantenimiento de tests
                        automatizados versus costos de testing manual repetido. Para tests que se ejecutan frecuentemente (por
                        ejemplo, en cada commit en CI), la automatización típicamente se paga rápidamente. Para tests ejecutados
                        raramente o que requieren juicio humano significativo, testing manual puede ser más económico. La decisión
                        de automatizar debe considerar: frecuencia de ejecución, estabilidad de funcionalidad (funcionalidad
                        cambiante requiere actualizar tests), complejidad de automatización, y criticidad de funcionalidad. No todo
                        testing debe o puede automatizarse; el arte consiste en seleccionar estratégicamente qué automatizar para
                        maximizar valor de inversión limitada.
                    </p>

                    <div class="important-box">
                        <h4>Reflexión: Testing como Actividad de Ingeniería</h4>
                        <p>
                            El testing de software ha evolucionado de actividad ad-hoc de verificación posterior a desarrollo
                            hacia disciplina de ingeniería sofisticada integrada en todo el ciclo de vida. El testing efectivo
                            requiere no solo ejecución de tests sino diseño estratégico de qué testear, cuándo, cómo y cuánto.
                            Los directores de proyectos deben reconocer que inversión en calidad mediante testing comprehensivo,
                            bien diseñado y apropiadamente automatizado constituye decisión económicamente racional que reduce
                            costos de defectos post-release, mejora satisfacción de clientes y facilita velocidad sostenible de
                            desarrollo. La calidad no puede inspeccionarse en un producto; debe construirse sistemáticamente mediante
                            prácticas de ingeniería rigurosas donde el testing juega rol central.
                        </p>
                    </div>
                </section>

                <div class="class-navigation">
                    <a href="clase-13.html" class="nav-button prev">Clase Anterior</a>
                    <a href="clase-15.html" class="nav-button next">Siguiente Clase</a>
                </div>
            </article>
        </main>
    </div>

    <footer>
        <p>&copy; 2025 Universidad Abierta Interamericana - Especialización en Dirección de Proyectos de Tecnología Informática</p>
        <p>Dictamen CONEAU Sesión N° 619 - RCS 6350/23</p>
    </footer>
</body>
</html>